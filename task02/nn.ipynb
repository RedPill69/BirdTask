{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from data_loader import load\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96000, 548) (96000,) (96000,) (24000, 548) (24000,)\n"
     ]
    }
   ],
   "source": [
    "#X_train, y_train: use for training and validating\n",
    "#stratify_criterion: used to make sure each fold in cross validation has the same annotator agreement distribution\n",
    "#X_test, y_test: only use for estimating final performance, prof really emphasized this (weird kink but ok)\n",
    "X_train, y_train, stratify_criterion, X_test, y_test = load()\n",
    "\n",
    "print(X_train.shape, y_train.shape, stratify_criterion.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Fold 1\n",
      "===============================\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.904940  [   64/64000]\n",
      "loss: 0.253511  [ 6464/64000]\n",
      "loss: 0.444626  [12864/64000]\n",
      "loss: 0.180425  [19264/64000]\n",
      "loss: 0.267905  [25664/64000]\n",
      "loss: 0.021022  [32064/64000]\n",
      "loss: 0.972238  [38464/64000]\n",
      "loss: 0.143013  [44864/64000]\n",
      "loss: 0.007163  [51264/64000]\n",
      "loss: 0.385664  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 1.216759 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.567226  [   64/64000]\n",
      "loss: 0.130201  [ 6464/64000]\n",
      "loss: 0.358334  [12864/64000]\n",
      "loss: 0.127221  [19264/64000]\n",
      "loss: 0.179912  [25664/64000]\n",
      "loss: 0.012853  [32064/64000]\n",
      "loss: 0.027096  [38464/64000]\n",
      "loss: 0.181500  [44864/64000]\n",
      "loss: 0.004888  [51264/64000]\n",
      "loss: 0.177110  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.990567 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.320066  [   64/64000]\n",
      "loss: 0.085550  [ 6464/64000]\n",
      "loss: 0.280293  [12864/64000]\n",
      "loss: 0.130426  [19264/64000]\n",
      "loss: 0.107230  [25664/64000]\n",
      "loss: 0.006911  [32064/64000]\n",
      "loss: 0.007699  [38464/64000]\n",
      "loss: 0.216363  [44864/64000]\n",
      "loss: 0.004498  [51264/64000]\n",
      "loss: 0.104336  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.892006 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.865628  [   64/64000]\n",
      "loss: 0.062594  [ 6464/64000]\n",
      "loss: 0.249508  [12864/64000]\n",
      "loss: 0.133605  [19264/64000]\n",
      "loss: 0.081733  [25664/64000]\n",
      "loss: 0.005493  [32064/64000]\n",
      "loss: 0.005165  [38464/64000]\n",
      "loss: 0.239569  [44864/64000]\n",
      "loss: 0.003924  [51264/64000]\n",
      "loss: 0.090377  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.850559 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.513888  [   64/64000]\n",
      "loss: 0.051084  [ 6464/64000]\n",
      "loss: 0.231255  [12864/64000]\n",
      "loss: 0.133508  [19264/64000]\n",
      "loss: 0.071378  [25664/64000]\n",
      "loss: 0.004953  [32064/64000]\n",
      "loss: 0.004378  [38464/64000]\n",
      "loss: 0.250425  [44864/64000]\n",
      "loss: 0.003418  [51264/64000]\n",
      "loss: 0.089068  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.828954 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.281988  [   64/64000]\n",
      "loss: 0.045213  [ 6464/64000]\n",
      "loss: 0.221636  [12864/64000]\n",
      "loss: 0.132335  [19264/64000]\n",
      "loss: 0.067068  [25664/64000]\n",
      "loss: 0.004669  [32064/64000]\n",
      "loss: 0.004218  [38464/64000]\n",
      "loss: 0.253523  [44864/64000]\n",
      "loss: 0.003067  [51264/64000]\n",
      "loss: 0.090380  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.814387 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.111561  [   64/64000]\n",
      "loss: 0.041966  [ 6464/64000]\n",
      "loss: 0.217065  [12864/64000]\n",
      "loss: 0.130543  [19264/64000]\n",
      "loss: 0.065225  [25664/64000]\n",
      "loss: 0.004509  [32064/64000]\n",
      "loss: 0.004430  [38464/64000]\n",
      "loss: 0.254310  [44864/64000]\n",
      "loss: 0.002924  [51264/64000]\n",
      "loss: 0.090429  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.803568 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.972881  [   64/64000]\n",
      "loss: 0.039413  [ 6464/64000]\n",
      "loss: 0.213673  [12864/64000]\n",
      "loss: 0.128704  [19264/64000]\n",
      "loss: 0.064318  [25664/64000]\n",
      "loss: 0.004343  [32064/64000]\n",
      "loss: 0.004709  [38464/64000]\n",
      "loss: 0.254764  [44864/64000]\n",
      "loss: 0.002937  [51264/64000]\n",
      "loss: 0.089002  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.796579 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.853828  [   64/64000]\n",
      "loss: 0.037454  [ 6464/64000]\n",
      "loss: 0.211540  [12864/64000]\n",
      "loss: 0.127123  [19264/64000]\n",
      "loss: 0.063437  [25664/64000]\n",
      "loss: 0.004165  [32064/64000]\n",
      "loss: 0.004907  [38464/64000]\n",
      "loss: 0.255250  [44864/64000]\n",
      "loss: 0.003048  [51264/64000]\n",
      "loss: 0.087175  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.790597 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.727627  [   64/64000]\n",
      "loss: 0.035962  [ 6464/64000]\n",
      "loss: 0.208952  [12864/64000]\n",
      "loss: 0.124870  [19264/64000]\n",
      "loss: 0.062551  [25664/64000]\n",
      "loss: 0.003988  [32064/64000]\n",
      "loss: 0.005210  [38464/64000]\n",
      "loss: 0.254042  [44864/64000]\n",
      "loss: 0.003229  [51264/64000]\n",
      "loss: 0.084841  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.786680 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.594991  [   64/64000]\n",
      "loss: 0.034773  [ 6464/64000]\n",
      "loss: 0.204885  [12864/64000]\n",
      "loss: 0.122437  [19264/64000]\n",
      "loss: 0.061846  [25664/64000]\n",
      "loss: 0.003801  [32064/64000]\n",
      "loss: 0.005768  [38464/64000]\n",
      "loss: 0.251539  [44864/64000]\n",
      "loss: 0.003498  [51264/64000]\n",
      "loss: 0.083019  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.783785 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.435166  [   64/64000]\n",
      "loss: 0.033764  [ 6464/64000]\n",
      "loss: 0.201642  [12864/64000]\n",
      "loss: 0.119975  [19264/64000]\n",
      "loss: 0.060912  [25664/64000]\n",
      "loss: 0.003615  [32064/64000]\n",
      "loss: 0.006271  [38464/64000]\n",
      "loss: 0.248225  [44864/64000]\n",
      "loss: 0.003751  [51264/64000]\n",
      "loss: 0.080744  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.780773 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.263594  [   64/64000]\n",
      "loss: 0.033041  [ 6464/64000]\n",
      "loss: 0.198452  [12864/64000]\n",
      "loss: 0.117385  [19264/64000]\n",
      "loss: 0.060063  [25664/64000]\n",
      "loss: 0.003416  [32064/64000]\n",
      "loss: 0.006870  [38464/64000]\n",
      "loss: 0.245555  [44864/64000]\n",
      "loss: 0.003977  [51264/64000]\n",
      "loss: 0.078426  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.778457 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.052391  [   64/64000]\n",
      "loss: 0.032005  [ 6464/64000]\n",
      "loss: 0.196449  [12864/64000]\n",
      "loss: 0.114993  [19264/64000]\n",
      "loss: 0.059081  [25664/64000]\n",
      "loss: 0.003226  [32064/64000]\n",
      "loss: 0.007556  [38464/64000]\n",
      "loss: 0.239568  [44864/64000]\n",
      "loss: 0.004244  [51264/64000]\n",
      "loss: 0.076247  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.776834 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.841722  [   64/64000]\n",
      "loss: 0.031038  [ 6464/64000]\n",
      "loss: 0.193364  [12864/64000]\n",
      "loss: 0.112176  [19264/64000]\n",
      "loss: 0.058269  [25664/64000]\n",
      "loss: 0.003037  [32064/64000]\n",
      "loss: 0.008453  [38464/64000]\n",
      "loss: 0.235070  [44864/64000]\n",
      "loss: 0.004352  [51264/64000]\n",
      "loss: 0.074592  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.775839 \n",
      "\n",
      "===============================\n",
      "Fold 2\n",
      "===============================\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.067694  [   64/64000]\n",
      "loss: 0.747436  [ 6464/64000]\n",
      "loss: 0.487883  [12864/64000]\n",
      "loss: 0.706823  [19264/64000]\n",
      "loss: 0.188369  [25664/64000]\n",
      "loss: 0.077043  [32064/64000]\n",
      "loss: 0.191886  [38464/64000]\n",
      "loss: 0.128851  [44864/64000]\n",
      "loss: 0.229593  [51264/64000]\n",
      "loss: 0.120201  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.968265 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.915874  [   64/64000]\n",
      "loss: 0.318629  [ 6464/64000]\n",
      "loss: 0.333494  [12864/64000]\n",
      "loss: 0.522102  [19264/64000]\n",
      "loss: 0.134888  [25664/64000]\n",
      "loss: 0.064382  [32064/64000]\n",
      "loss: 0.156073  [38464/64000]\n",
      "loss: 0.169000  [44864/64000]\n",
      "loss: 0.114840  [51264/64000]\n",
      "loss: 0.097289  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.782585 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.331770  [   64/64000]\n",
      "loss: 0.256792  [ 6464/64000]\n",
      "loss: 0.252279  [12864/64000]\n",
      "loss: 0.446887  [19264/64000]\n",
      "loss: 0.123644  [25664/64000]\n",
      "loss: 0.062078  [32064/64000]\n",
      "loss: 0.128003  [38464/64000]\n",
      "loss: 0.205970  [44864/64000]\n",
      "loss: 0.082412  [51264/64000]\n",
      "loss: 0.097721  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.697005 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.685568  [   64/64000]\n",
      "loss: 0.233285  [ 6464/64000]\n",
      "loss: 0.221119  [12864/64000]\n",
      "loss: 0.407266  [19264/64000]\n",
      "loss: 0.116574  [25664/64000]\n",
      "loss: 0.059285  [32064/64000]\n",
      "loss: 0.106148  [38464/64000]\n",
      "loss: 0.226533  [44864/64000]\n",
      "loss: 0.071498  [51264/64000]\n",
      "loss: 0.100822  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.658422 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.432352  [   64/64000]\n",
      "loss: 0.220114  [ 6464/64000]\n",
      "loss: 0.200642  [12864/64000]\n",
      "loss: 0.404029  [19264/64000]\n",
      "loss: 0.110667  [25664/64000]\n",
      "loss: 0.057273  [32064/64000]\n",
      "loss: 0.089244  [38464/64000]\n",
      "loss: 0.238220  [44864/64000]\n",
      "loss: 0.062459  [51264/64000]\n",
      "loss: 0.103703  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.635786 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.231855  [   64/64000]\n",
      "loss: 0.210945  [ 6464/64000]\n",
      "loss: 0.187008  [12864/64000]\n",
      "loss: 0.409505  [19264/64000]\n",
      "loss: 0.105559  [25664/64000]\n",
      "loss: 0.054851  [32064/64000]\n",
      "loss: 0.073919  [38464/64000]\n",
      "loss: 0.244490  [44864/64000]\n",
      "loss: 0.055138  [51264/64000]\n",
      "loss: 0.107445  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.619535 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.049677  [   64/64000]\n",
      "loss: 0.203708  [ 6464/64000]\n",
      "loss: 0.177493  [12864/64000]\n",
      "loss: 0.417306  [19264/64000]\n",
      "loss: 0.102034  [25664/64000]\n",
      "loss: 0.052417  [32064/64000]\n",
      "loss: 0.063020  [38464/64000]\n",
      "loss: 0.245718  [44864/64000]\n",
      "loss: 0.050125  [51264/64000]\n",
      "loss: 0.110629  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.607967 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.895609  [   64/64000]\n",
      "loss: 0.198466  [ 6464/64000]\n",
      "loss: 0.170387  [12864/64000]\n",
      "loss: 0.419596  [19264/64000]\n",
      "loss: 0.099543  [25664/64000]\n",
      "loss: 0.049893  [32064/64000]\n",
      "loss: 0.056217  [38464/64000]\n",
      "loss: 0.242478  [44864/64000]\n",
      "loss: 0.045908  [51264/64000]\n",
      "loss: 0.113585  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.599540 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.750738  [   64/64000]\n",
      "loss: 0.194214  [ 6464/64000]\n",
      "loss: 0.163800  [12864/64000]\n",
      "loss: 0.421779  [19264/64000]\n",
      "loss: 0.097565  [25664/64000]\n",
      "loss: 0.047877  [32064/64000]\n",
      "loss: 0.052110  [38464/64000]\n",
      "loss: 0.238281  [44864/64000]\n",
      "loss: 0.042698  [51264/64000]\n",
      "loss: 0.116566  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.593539 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.615946  [   64/64000]\n",
      "loss: 0.188319  [ 6464/64000]\n",
      "loss: 0.156405  [12864/64000]\n",
      "loss: 0.422428  [19264/64000]\n",
      "loss: 0.094748  [25664/64000]\n",
      "loss: 0.045429  [32064/64000]\n",
      "loss: 0.047623  [38464/64000]\n",
      "loss: 0.233880  [44864/64000]\n",
      "loss: 0.039809  [51264/64000]\n",
      "loss: 0.119174  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.589231 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.487955  [   64/64000]\n",
      "loss: 0.183971  [ 6464/64000]\n",
      "loss: 0.150043  [12864/64000]\n",
      "loss: 0.419506  [19264/64000]\n",
      "loss: 0.091951  [25664/64000]\n",
      "loss: 0.043392  [32064/64000]\n",
      "loss: 0.044143  [38464/64000]\n",
      "loss: 0.225720  [44864/64000]\n",
      "loss: 0.037279  [51264/64000]\n",
      "loss: 0.120998  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.586624 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.363384  [   64/64000]\n",
      "loss: 0.175847  [ 6464/64000]\n",
      "loss: 0.144958  [12864/64000]\n",
      "loss: 0.411729  [19264/64000]\n",
      "loss: 0.089193  [25664/64000]\n",
      "loss: 0.041260  [32064/64000]\n",
      "loss: 0.041719  [38464/64000]\n",
      "loss: 0.214827  [44864/64000]\n",
      "loss: 0.034967  [51264/64000]\n",
      "loss: 0.123237  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.584989 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.241243  [   64/64000]\n",
      "loss: 0.168483  [ 6464/64000]\n",
      "loss: 0.140489  [12864/64000]\n",
      "loss: 0.406620  [19264/64000]\n",
      "loss: 0.086320  [25664/64000]\n",
      "loss: 0.038769  [32064/64000]\n",
      "loss: 0.040201  [38464/64000]\n",
      "loss: 0.206382  [44864/64000]\n",
      "loss: 0.032850  [51264/64000]\n",
      "loss: 0.124968  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.584562 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.143872  [   64/64000]\n",
      "loss: 0.159150  [ 6464/64000]\n",
      "loss: 0.135777  [12864/64000]\n",
      "loss: 0.400396  [19264/64000]\n",
      "loss: 0.082812  [25664/64000]\n",
      "loss: 0.036916  [32064/64000]\n",
      "loss: 0.037910  [38464/64000]\n",
      "loss: 0.197318  [44864/64000]\n",
      "loss: 0.030922  [51264/64000]\n",
      "loss: 0.126381  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.583619 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.046340  [   64/64000]\n",
      "loss: 0.151541  [ 6464/64000]\n",
      "loss: 0.131173  [12864/64000]\n",
      "loss: 0.389208  [19264/64000]\n",
      "loss: 0.078942  [25664/64000]\n",
      "loss: 0.034904  [32064/64000]\n",
      "loss: 0.034933  [38464/64000]\n",
      "loss: 0.187736  [44864/64000]\n",
      "loss: 0.028914  [51264/64000]\n",
      "loss: 0.126534  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.583631 \n",
      "\n",
      "===============================\n",
      "Fold 3\n",
      "===============================\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.031330  [   64/64000]\n",
      "loss: 0.660908  [ 6464/64000]\n",
      "loss: 0.474275  [12864/64000]\n",
      "loss: 0.627603  [19264/64000]\n",
      "loss: 0.253637  [25664/64000]\n",
      "loss: 0.039385  [32064/64000]\n",
      "loss: 1.331357  [38464/64000]\n",
      "loss: 0.256923  [44864/64000]\n",
      "loss: 0.034817  [51264/64000]\n",
      "loss: 0.360320  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.302258 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 5.267636  [   64/64000]\n",
      "loss: 0.294992  [ 6464/64000]\n",
      "loss: 0.453777  [12864/64000]\n",
      "loss: 0.449681  [19264/64000]\n",
      "loss: 0.185516  [25664/64000]\n",
      "loss: 0.038060  [32064/64000]\n",
      "loss: 1.139458  [38464/64000]\n",
      "loss: 0.207550  [44864/64000]\n",
      "loss: 0.027415  [51264/64000]\n",
      "loss: 0.262879  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 1.249638 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.745840  [   64/64000]\n",
      "loss: 0.236552  [ 6464/64000]\n",
      "loss: 0.424096  [12864/64000]\n",
      "loss: 0.415975  [19264/64000]\n",
      "loss: 0.172348  [25664/64000]\n",
      "loss: 0.032352  [32064/64000]\n",
      "loss: 0.935259  [38464/64000]\n",
      "loss: 0.182217  [44864/64000]\n",
      "loss: 0.026341  [51264/64000]\n",
      "loss: 0.232136  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 1.169914 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.511724  [   64/64000]\n",
      "loss: 0.229819  [ 6464/64000]\n",
      "loss: 0.393017  [12864/64000]\n",
      "loss: 0.388831  [19264/64000]\n",
      "loss: 0.162048  [25664/64000]\n",
      "loss: 0.027378  [32064/64000]\n",
      "loss: 0.776376  [38464/64000]\n",
      "loss: 0.186861  [44864/64000]\n",
      "loss: 0.025438  [51264/64000]\n",
      "loss: 0.212044  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.151671 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.117070  [   64/64000]\n",
      "loss: 0.227071  [ 6464/64000]\n",
      "loss: 0.362733  [12864/64000]\n",
      "loss: 0.379243  [19264/64000]\n",
      "loss: 0.155991  [25664/64000]\n",
      "loss: 0.023744  [32064/64000]\n",
      "loss: 0.649904  [38464/64000]\n",
      "loss: 0.194017  [44864/64000]\n",
      "loss: 0.025599  [51264/64000]\n",
      "loss: 0.199816  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.150818 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.918961  [   64/64000]\n",
      "loss: 0.219767  [ 6464/64000]\n",
      "loss: 0.336031  [12864/64000]\n",
      "loss: 0.381797  [19264/64000]\n",
      "loss: 0.150673  [25664/64000]\n",
      "loss: 0.021059  [32064/64000]\n",
      "loss: 0.546204  [38464/64000]\n",
      "loss: 0.195158  [44864/64000]\n",
      "loss: 0.025909  [51264/64000]\n",
      "loss: 0.193846  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 1.153353 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.774322  [   64/64000]\n",
      "loss: 0.211538  [ 6464/64000]\n",
      "loss: 0.312799  [12864/64000]\n",
      "loss: 0.386473  [19264/64000]\n",
      "loss: 0.145279  [25664/64000]\n",
      "loss: 0.019123  [32064/64000]\n",
      "loss: 0.462976  [38464/64000]\n",
      "loss: 0.180587  [44864/64000]\n",
      "loss: 0.026873  [51264/64000]\n",
      "loss: 0.188923  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.155473 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.639560  [   64/64000]\n",
      "loss: 0.200294  [ 6464/64000]\n",
      "loss: 0.291443  [12864/64000]\n",
      "loss: 0.389264  [19264/64000]\n",
      "loss: 0.139434  [25664/64000]\n",
      "loss: 0.017801  [32064/64000]\n",
      "loss: 0.400980  [38464/64000]\n",
      "loss: 0.144736  [44864/64000]\n",
      "loss: 0.027936  [51264/64000]\n",
      "loss: 0.184850  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 1.155606 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.513342  [   64/64000]\n",
      "loss: 0.190678  [ 6464/64000]\n",
      "loss: 0.274706  [12864/64000]\n",
      "loss: 0.391394  [19264/64000]\n",
      "loss: 0.134028  [25664/64000]\n",
      "loss: 0.016701  [32064/64000]\n",
      "loss: 0.349623  [38464/64000]\n",
      "loss: 0.119620  [44864/64000]\n",
      "loss: 0.029034  [51264/64000]\n",
      "loss: 0.179883  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 1.156553 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.405731  [   64/64000]\n",
      "loss: 0.181974  [ 6464/64000]\n",
      "loss: 0.260948  [12864/64000]\n",
      "loss: 0.387530  [19264/64000]\n",
      "loss: 0.129225  [25664/64000]\n",
      "loss: 0.015825  [32064/64000]\n",
      "loss: 0.309478  [38464/64000]\n",
      "loss: 0.097453  [44864/64000]\n",
      "loss: 0.029654  [51264/64000]\n",
      "loss: 0.175623  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 1.157362 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.298939  [   64/64000]\n",
      "loss: 0.175148  [ 6464/64000]\n",
      "loss: 0.247957  [12864/64000]\n",
      "loss: 0.382280  [19264/64000]\n",
      "loss: 0.125021  [25664/64000]\n",
      "loss: 0.015110  [32064/64000]\n",
      "loss: 0.277665  [38464/64000]\n",
      "loss: 0.082029  [44864/64000]\n",
      "loss: 0.029848  [51264/64000]\n",
      "loss: 0.171073  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 1.164026 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.208445  [   64/64000]\n",
      "loss: 0.167366  [ 6464/64000]\n",
      "loss: 0.237047  [12864/64000]\n",
      "loss: 0.373090  [19264/64000]\n",
      "loss: 0.121279  [25664/64000]\n",
      "loss: 0.014379  [32064/64000]\n",
      "loss: 0.252684  [38464/64000]\n",
      "loss: 0.067939  [44864/64000]\n",
      "loss: 0.029540  [51264/64000]\n",
      "loss: 0.166739  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.172240 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.124703  [   64/64000]\n",
      "loss: 0.160006  [ 6464/64000]\n",
      "loss: 0.226235  [12864/64000]\n",
      "loss: 0.363362  [19264/64000]\n",
      "loss: 0.117693  [25664/64000]\n",
      "loss: 0.013823  [32064/64000]\n",
      "loss: 0.232080  [38464/64000]\n",
      "loss: 0.052418  [44864/64000]\n",
      "loss: 0.029224  [51264/64000]\n",
      "loss: 0.162121  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.184546 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.040628  [   64/64000]\n",
      "loss: 0.150413  [ 6464/64000]\n",
      "loss: 0.215362  [12864/64000]\n",
      "loss: 0.349925  [19264/64000]\n",
      "loss: 0.114521  [25664/64000]\n",
      "loss: 0.013286  [32064/64000]\n",
      "loss: 0.217452  [38464/64000]\n",
      "loss: 0.043024  [44864/64000]\n",
      "loss: 0.028584  [51264/64000]\n",
      "loss: 0.157931  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.197755 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.974119  [   64/64000]\n",
      "loss: 0.141416  [ 6464/64000]\n",
      "loss: 0.204341  [12864/64000]\n",
      "loss: 0.337920  [19264/64000]\n",
      "loss: 0.112207  [25664/64000]\n",
      "loss: 0.012853  [32064/64000]\n",
      "loss: 0.204233  [38464/64000]\n",
      "loss: 0.038981  [44864/64000]\n",
      "loss: 0.028059  [51264/64000]\n",
      "loss: 0.152788  [57664/64000]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.214943 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "skf = StratifiedKFold(3)\n",
    "scaler = StandardScaler()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "for i, (train_index, validate_index) in enumerate(skf.split(X_train, stratify_criterion)):\n",
    "    \n",
    "    print(f\"===============================\\nFold {i+1}\\n===============================\")\n",
    "\n",
    "    X_fold = X_train[train_index]\n",
    "    scaler.fit(X_fold)\n",
    "    X_fold = scaler.transform(X_fold)\n",
    "    X_fold = torch.Tensor(X_fold).to(device)\n",
    "\n",
    "    y_fold = y_train[train_index]\n",
    "    y_fold = np.eye(7)[y_fold]\n",
    "    y_fold = torch.Tensor(y_fold).to(device)\n",
    "\n",
    "    X_validate = X_train[validate_index]\n",
    "    X_validate = scaler.transform(X_validate)\n",
    "    X_validate = torch.Tensor(X_validate).to(device)\n",
    "\n",
    "    y_validate = y_train[validate_index]\n",
    "    y_validate = np.eye(7)[y_validate]\n",
    "    y_validate = torch.Tensor(y_validate).to(device)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(548, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 7)\n",
    "    ).to(device)\n",
    "\n",
    "    train_dataloader = DataLoader(TensorDataset(X_fold, y_fold), batch_size=64)\n",
    "    test_dataloader = DataLoader(TensorDataset(X_validate, y_validate))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "    epochs = 15\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test(test_dataloader, model, loss_fn)\n",
    "    \n",
    "\n",
    "#estimate actual performance on best classifier with X_test and y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
